# Building Your AI Workforce

## Work Has Been Eliminated Before (And Nobody Mourns It)

In 1900, harvesting a hundred acres of wheat took dozens of laborers. Weeks of backbreaking work. Cutting by hand with scythes. Bundling the stalks. Threshing to separate grain from chaff. Loading wagons by pitchfork.

Whole families worked the harvest. Children too. People got injured. Some died. This was simply what harvest meant. There was no alternative.

Today: one combine harvester, one operator, air-conditioned cab, GPS-guided, a few hours. The machine cuts, threshes, and loads in a single pass. One person does what once required an entire community bent to the task.

That transition eliminated work. Entire ways of life disappeared. But nobody wishes we still had children in fields with scythes. The work that was eliminated was work that should have been eliminated. The people who did it deserved better than that work.

If you wanted to make a phone call in the early 1900s, you couldn't just dial. You picked up the phone and a voice answered: "Number please."

That was a switchboard operator. Usually a young woman. She sat at a massive board with hundreds of cables and jacks. You told her who you wanted to reach. She physically plugged a cable to connect your line to theirs. Every call required a human hand making a physical connection.

In 1920, there were over 200,000 switchboard operators in America. Big cities had entire buildings full of them. Banks of women, headsets on, plugging and unplugging cables all day long. This was a real profession. People built lives around it.

Then came direct dial. You could connect yourself.

By the 1980s, the job was essentially gone. No more "Number please." The work was eliminated. Communication got better, faster, cheaper. Nobody wants to go back.

Before the electronic computer existed, "computer" was a job title. It meant: a person who computes.

Rooms of people—usually women, because they were cheaper to hire—doing calculations by hand. Pencil, paper, slide rules, mechanical adding machines. Hour after hour of arithmetic.

NASA had them. That's what the movie "Hidden Figures" is about. Katherine Johnson, Dorothy Vaughan, Mary Jackson: human computers calculating rocket trajectories by hand. They were essential to the space program. The astronauts trusted their lives to these women's calculations.

Banks had them. Insurance companies had actuarial departments full of them. Artillery units had them calculating firing tables. These were skilled workers. Smart, meticulous, often college-educated. The work required precision. An error in calculation could mean a rocket missing its target or an insurance company going bankrupt.

In 1942, if you had differential calculus and physics, you could get hired on the spot. The interviewer would ask: "Did you have differential calculus?" Yes. "Did you have physics?" Yes. "You are exactly what we need."

Your civil service paperwork would say your job title: Computer. Capital C.

The federal government had pay grades for it. Junior Computer: $1,440 a year. Computer: $1,620. Chief Computer: $3,200. This was real work, a real profession, with a career ladder.

Your job: 30 to 40 hours of hand calculations to compute a single artillery trajectory. One trajectory. Forty hours of a brilliant person's time.

Then electronic computers arrived. Faster. More accurate. Tireless.

Now your phone does those calculations in milliseconds. The machine has the name. We don't even remember that "computer" used to mean a person.

The work was eliminated. But that work—calculating the same formulas over and over, checking each other's arithmetic—was not work that used the full potential of those brilliant women. Katherine Johnson became an engineer and made contributions no machine could make. The elimination of that work freed her for work worthy of her mind.

None of us mourn these jobs. The work that was eliminated was work that should have been eliminated. The people who did it deserved better than that work.

Their grandchildren are accountants, engineers, teachers, business owners. Some of them are probably in every room where business leaders gather.

AI is the next one.

The question is: what's the equivalent in your business today? What work should be eliminated? What work are your people doing that they deserve better than?


## Why "Tool" Is the Wrong Frame for AI

You've bought technology before. You have a mental model.

Technology is a tool. You evaluate features. Compare vendors. Calculate ROI based on cost and expected output. Buy it, configure it, train people on it, roll it out. This is how technology has worked for your entire career.

This frame has been sold to you for decades.

CRM promised revenue growth. "Buy this, your revenue will grow." The technology causes the outcome. That was the pitch.

Salesforce is worth $200 billion. Companies run on CRM. It works.

But what does it actually deliver? Visibility. Reporting. Data structure. Accountability. That's real value. But it's infrastructure. It's capability.

The companies that grew revenue had something else underneath. A sales process that worked. A culture where reps believed in the process. Management that paid attention to what the data revealed and actually did something about it.

The CRM amplified what was already there.

The companies that didn't grow had the same CRM. Same features. Same implementation partner. Same training. But nothing underneath. So they got a database. Expensive data entry. Reports nobody trusted because the data was bad because nobody cared because there was no culture making them care.

Same technology. Wildly different outcomes. The difference was invisible at purchase time.

I saw a banner in Staples. They were selling a chair. The banner said "Sit like a CEO."

That's the promise. Buy this thing, become this person.

It's absurd for a chair. But it's exactly how enterprise software has been sold for forty years. Buy this CRM, grow revenue. Buy this ERP, optimize operations. Buy this platform, transform your business.

The technology is real. The promise is a category error.

Technology is an amplifier. It amplifies what's there.

Good process plus CRM equals better process, more visible, more measurable. No process plus CRM equals expensive nothing.

Now AI arrives. Same pattern loading.

"Buy AI. Automate workflows. Get productivity."

But there's a compounding problem.

For CRM and ERP, "tool" was the right category. They ARE tools. You configure them. They do what you set up. The frame was accurate. The expectation was wrong.

For AI, "tool" is the wrong category entirely.

AI initiates. It doesn't wait for you to act. A tool sits there until you pick it up. AI can start things.

AI has judgment. Not human judgment, but something you have to calibrate. A tool does exactly what you tell it. AI makes decisions within parameters you set.

AI operates with autonomy. Autonomy you design, but autonomy nonetheless. A tool has no autonomy. AI can run without you.

AI develops over time. It changes with use, feedback, context. A tool is the same tool tomorrow that it was today. AI learns.

This doesn't describe a tool. It describes something else.


## AI Workers Are Workers: Manage Them Like Workers

AI workers are workers. Not software. Workers.

You don't ask "what can this tool do?" You ask: what's the job? Who supervises? Is the workflow ready?

Think about roles in your company.

Someone reconciles invoices. They receive invoices, match them to POs, flag discrepancies, route for approval. That's a job with an outcome: invoices reconciled accurately and timely.

An AI worker can own that outcome. Not "invoice processing" as a feature. Own the reconciliation. Run it. Flag what needs attention.

Someone follows up on collections. Pulls aging reports, decides who to contact, drafts emails, tracks responses. That's a job with an outcome: receivables collected, cash flow protected.

An AI worker can own that outcome. Monitor continuously. Trigger follow-ups based on rules. Escalate based on amount and age.

The tool frame asks: Does this software have invoice processing?

The worker frame asks: What outcome does this worker own? What decisions can they make alone? Where do they need supervision?

Different questions. Different downstream.

You already know how to think about this.

When you hire, you don't evaluate based on features. You define the role first. What outcome does this role own?

You know new hires ramp up. Month one isn't full capacity. Year one is learning. You don't expect a new hire to be fully productive on day one.

You know some roles need close supervision. Others you let run. Junior employees check in frequently. Senior employees you trust with more autonomy.

You manage people continuously. Pay attention to performance. Develop capabilities. Adjust responsibilities based on what you learn about someone's strengths.

This is the framework. Management.

You haven't applied it to AI because everyone's been selling AI as technology. But you have the mental model. It needs translating, not learning from scratch.

Some workers you want supervised. They prepare, you approve, they execute. High stakes, judgment-heavy.

Some workers you want autonomous. They run, you see exceptions. High volume, clear rules.

Same underlying technology. Different relationship. Your choice based on what the work requires.


## **The Leadership Questions** → **Four Questions Before Building Your AI Workforce**

Before you pick which workflow to automate, before you evaluate vendors, before you build anything, there are four questions. They're not about technology. They're about leadership.

Most AI adoption fails because the organization's decision-making apparatus is clouded.

Sometimes it's a well-meaning but misguided technical person who has the wrong mental model and enough influence to shape direction. Sometimes it's leadership that hasn't examined its own stance. Sometimes it's a culture that sees people as expense rather than trapped value.

Before you can select the right workflow, you need alignment on something deeper. The entire decision-making apparatus—leadership, department heads, the people who will live with this—needs clarity.

**What's our stance?**

Are we resisting, accepting, or participating?

Resisting looks like: "We'll wait and see." "Our industry is different." "AI isn't ready yet." It's often disguised as prudence. But the combine harvester didn't wait for farmers to be ready. Direct dial didn't wait for switchboard operators to adjust.

Accepting looks like: "We have to do something." It's reactive. Defensive. Usually produces scattered pilots that don't connect, purchased tools that don't get used, and a growing sense that "AI doesn't work for us."

Participating looks like: "We're inside a transition. We know how these end. Our job is to move through it well." It's active, not reactive. It starts with stance, not tools.

The organization takes its cue from leadership's actual stance—not the words, the stance. People can tell the difference. If leadership is secretly resisting while publicly accepting, the organization feels the contradiction and hedges accordingly.

What's your actual stance? Not what you say in meetings. What you believe when you're being honest with yourself.

**How do we see our people?**

Are they expense to minimize? Or value currently trapped in soul-crushing work?

This isn't soft. It's strategic.

If you see people as expense, AI becomes a headcount reduction tool. Automate everything. Measure success by humans removed. That works in the short term. Then the company gets brittle. It can execute but can't adapt. It can produce but can't judge. The humans who remain are anxious and disengaged. The humans who left took institutional knowledge with them.

If you see people as trapped value, AI becomes a liberation tool. What are your people doing that they don't actually enjoy, that doesn't use their real capabilities, that AI could do better, faster, cheaper?

Who actually wants to go to five different websites to research and qualify a customer? Who enjoys keying invoices into databases? Who finds meaning in copying data between systems, chasing discrepancies, running the same reports from siloed SaaS platforms every month?

That work isn't worthy of the people doing it. They know it. You know it. AI can do it better—and your people can do something better.

The question isn't "how do we reduce headcount?" The question is "what could our people do if we freed them from the work that shouldn't be theirs?"

**Which future are we building?**

There are two ways this goes.

Future One: Replacement. AI is understood as a better, cheaper version of what humans do. The logic is clean: if the output is same or better and cost is lower, the human is overhead. Companies compete by removing humans from the loop. Work becomes a shrinking pie.

The human experience in this future: anxiety, hollowing, race to the bottom. Every new model release is a threat. Work becomes whatever AI can't do yet—the scraps. Human labor competes on cost with machines.

Future Two: Reveal. AI is understood as a different kind of capacity entirely. It handles generation, retrieval, processing, prediction. And precisely because AI handles that, something else becomes visible: what humans were always for underneath the tasks.

Judgment—discerning what's worth doing. Relationship—staying in the room when it's hard. Meaning—helping people understand what matters. Presence—holding the frame when things shake.

The human experience in this future: clarity, craft, dignity, partnership. AI becomes a tool that extends reach without replacing center. The division of labor is clear: AI generates, humans discern. AI processes, humans orient. AI predicts, humans decide.

Both futures are happening right now. Some companies racing toward Replacement. Some building toward Reveal. The technology doesn't determine which future you inhabit. Your understanding does.

Which future are you building toward?

**What are the activity streams?**

This is where it gets concrete.

Across all operations—core ops, sales ops, marketing ops, finance ops, IT ops, HR ops, training ops—there are activity streams. Things people do. Time they spend. Work that flows through the organization.

Some of that work should be eliminated. Data entry. Reconciliation. Copying between systems. Chasing discrepancies. Running reports in silos. Research that's the same research someone did last month.

Some of that work is worthy of humans. Judgment calls. Relationship building. Decisions that require context no system can see. The moments where someone needs a person, not a process.

What work should be eliminated across your operations? What work is worthy of humans?

Most leaders can't answer this clearly. Not because they're not smart. Because they've never been asked to look at it this way. The question itself is new.

But until you can answer it—until you can look at your operations and say "this work should be eliminated, this work is worthy of humans"—you're not ready to select workflows. You're guessing.

## Your People Are Doing Work Machines Should Do

Look at what your people actually spend time on.

Entering data in databases using many different applications. Exporting from one system, importing to another. Salesforce knows sales. QuickBooks knows accounting. Expensify knows expenses. None of them talk to each other. Your people are the connection.

Copying data between systems. Checking that things match. Chasing discrepancies. Running the same reports from five different platforms and manually combining them.

This is not work worthy of the people doing it. It's work machines should do. Your people have become glue between software that doesn't talk to itself.

Now imagine the shift.

AI workers see across systems. They make connections. They handle the routine. They surface the exceptions.

Your team sees exceptions. They make decisions. They do work only humans should do.

Your team stops being the integration layer and becomes the judgment layer. From glue to judgment. From doing what machines should do to doing what only humans can do.

Your job as a leader: figure out what work should be eliminated. Figure out what work is worthy of humans. Align your people and your technology so humans do human-worthy work and machines do the rest.


## One Firm, Four Departments, Five Workers

Let me show you what this looks like when you get it right.

Meridian Group. Fifty people. Professional services. The same departments you have: Finance, Sales, HR, Marketing. Five AI workers. Real workflows.

The AP Processing Worker owns invoice reconciliation. 750 invoices a month. 80% process without human touch. The human sees exceptions: new vendor, amount variance, possible duplicate. The human isn't doing data entry anymore. They're making decisions about the exceptions that require judgment.

This is cost reduction. Predictable ROI. The ceiling is your current spend—you can't save more than you're spending. But it's the safe starting point. Process is clear. Outcome is measurable. Risk is low.

The Pipeline Builder owns lead generation. Signal-based sourcing, filtering, scoring, validation. It finds prospects showing buying intent—job postings, funding announcements, technology changes, growth signals. It qualifies them before anyone spends time. The human reviews the list, not builds it.

This is revenue generation. There's no ceiling on ROI. If the worker finds you one deal you wouldn't have found, it paid for itself. If it finds you twenty, the math changes completely.

The Sales Outreach Worker owns personalization. It researches each prospect. Reads their posts, finds their writing, understands their context, crafts the first line that earns the open. The human approves and sends.

Why supervised? External communication. Stakes are different. You're not just processing internal data—you're representing your company to prospects. Trust is earned over time. The worker drafts, the human reviews, the worker sends. As you learn what works and build confidence, the autonomy can increase.

The Talent Hunter owns candidate discovery. It works in two modes. For hard-to-fill roles: passive sourcing, needle in haystack, finding people who aren't actively looking but might be open. For roles drowning in applications: smart filtering, 500 resumes become the ten worth reading.

Same pattern as sales outreach. Research, personalize, reach. Different target. The capability node is reusable. You learn it once. Apply it twice.

The Content Co-pilot assists marketing. This one is different. Human-led. The human creates; the worker assists. Retrieval, reasoning, memory. It knows the brand voice, the existing collateral, the positioning. It doesn't create from scratch. It helps the human who does.

This is Assistant, not Agent. The taxonomy distinction matters. Agent owns an outcome. Assistant extends human capability. Both are valuable. They're not the same.

Notice what's happening across these five workers.

AP is autonomous. Once it's trained and calibrated, it runs. Humans see exceptions, not transactions.

Sales and HR are supervised. External communication, higher stakes. Human in the loop for judgment and approval.

Content is human-led. The work requires human creativity. AI assists, doesn't own.

Three autonomy modes. One firm. The design choices aren't random. They're calibrated to stakes and trust.

Notice also: the ROI story changes by department.

Finance: cost reduction. Ceiling equals current spend. Predictable.

Sales and HR: revenue generation. No ceiling. One placement or one deal can pay for everything.

Marketing: leverage and quality. Multiplier on human creativity. Harder to measure, but real.

Three different value stories. One workforce.

Each of these workers is based on production systems built for real clients across professional services, manufacturing, and distribution. This isn't theory. This is what works.

## Three Questions for Every AI Worker

Every workflow. Every worker. Three questions.

**Is this process documented and measurable?**

If you can't describe it, you can't delegate it. This is true for human workers too. If you hire someone and can't tell them what the job is, they flounder. AI workers flounder the same way. Process clarity comes first.

**What outcome does this worker own?**

One sentence. Clear accountability. Not "helps with invoices" but "invoices processed accurately and timely." Not "assists with recruiting" but "qualified candidates surfaced for open roles." Specific enough that you'd know if it wasn't happening.

**Who supervises, and when do they intervene?**

Autonomy is designed, not assumed. Some workers run and you see exceptions. Some workers prepare and wait for approval. Some workers assist humans who lead. You decide based on stakes, trust, and what the work requires.


## The Close

In 1942, "Computer" was a job title. Capital C. Printed on civil service paperwork.

Your job: 30 to 40 hours of hand calculations for a single artillery trajectory.

Now your phone does that in milliseconds. And nobody mourns the job.

A hundred years from now, your great-grandchildren will look back at some of what we do today and feel the same way. "They used to manually key invoices into databases? They used to copy data between systems by hand? They used to spend days closing books that should close in hours? They used to research every prospect from scratch instead of letting machines do the filtering?"

You're in the middle of that transition.

Some of you are worried about being outcompeted by companies that figure this out faster. Valid concern.

Some of you are worried about your people. What happens to them? Also valid.

Some of you tried AI already and it didn't deliver what you hoped. You weren't stupid. You were sold the wrong frame.

All of these concerns point at something real. But they're not the core question.

The core question is: what's your stance?

If you're honest with yourself about your stance, you can be honest with your team. You can say: "This is what's happening. This is what work we're eliminating. This is what work we're elevating. And this is how we're going to do it together."

Then everyone who's willing to participate in the right spirit can capture value. Some people will resist. Some displacement will be painful. That's real.

But alignment starts with honesty. Honesty starts with your own stance.

Your job isn't to resist or accept. Your job is to participate well.

Figure out what work should be eliminated. Figure out what work is worthy of humans. Align your people and your technology so humans do human-worthy work and machines do the rest.

That's participating well.

That's what I hope you take from this. A way of seeing where you are. And the clarity to move through it.
